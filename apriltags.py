# Created by Alex Pereira

# Import Libraries
import cv2   as cv
import numpy as np
import collections
import transforms3d
import dt_apriltags
from apriltag import apriltag

# Creates the Detector Class
class Detector:
    def __init__(self) -> None:
        """
        Constructor for the Detector class.
        """
        # Creates an apriltag detector
        self.atdetector = apriltag("tag16h5")
        self.dtdetector = dt_apriltags.Detector(families="tag16h5", nthreads = 2500, quad_decimate = 1.0, quad_sigma = 0.0, refine_edges = True)

        # The size of the tag in meters
        self.tag_size = 0.1524

    def dtDetectTags(self, stream, camera_matrix, vizualization = 0, verbose = 0, annotate = False):
        """
        Detects AprilTags in a stream using dt_apriltags.
        @param stream: A stream generated by reading a VideoCapture
        @param camera_matrix: The camera's calibration matrix
        @param vizualization [int]: 0 - Highlight, 1 - Highlight + Boxes, 2 - Highlight + Axes, 3 - Highlight + Boxes + Axes
        @param verbose [int]: 0 - Silent, 1 - Number of detections, 2 - Detection data, 3 - Detection and pose data
        @param annotate [bool]: Render annotated text on detection window
        @return detectionResult, image
        """
        # If the stream is not grayscale, convert to grayscale
        if (len(stream.shape) == 3):
            gray = cv.cvtColor(stream, cv.COLOR_BGR2GRAY)
        else:
            gray = stream

        # Define the intrinsic parameters of the camera
        intrinsic_properties = (camera_matrix[0, 0], camera_matrix[1, 1], camera_matrix[0, 2], camera_matrix[1, 2])  # fx, fy, cx, cy

        # Detect the AprilTags in the image with Duckie Town Apriltags
        detections = self.dtdetector.detect(gray, estimate_tag_pose = True, camera_params = intrinsic_properties, tag_size = self.tag_size)

        # If verbose enabled, prints number of tags detected
        num_detections = len(detections)
        if (verbose == 1) or (verbose == 2) or (verbose == 3):
            print("Detected {} tags\n".format(num_detections))

        # Creates the result array
        result = []

        # Access the 3D pose of all detected tag
        for i, tag in enumerate(detections):
            # Gets info from the tag
            tag_num = tag.tag_id
            rMatrix = tag.pose_R
            tVecs   = tag.pose_t
            err     = tag.pose_err

            # Creates a 3d pose array from the rotation matrix and translation vectors
            pose = np.concatenate([rMatrix, tVecs], axis = 1)

            # Prints debug info
            if (verbose == 2) or (verbose == 3):
                print( "Detection {} of {}:".format(i + 1, num_detections))
                print(tag.tostring(indent = 2))

                np.reshape(1, 3)

            # Draws varying levels of information onto the image
            if (vizualization == 1):
                self.draw_pose_box(stream, camera_matrix, pose)
            elif (vizualization == 2):
                self.draw_pose_axes(stream, camera_matrix, pose, tag.center)
            elif (vizualization == 3):
                self.draw_pose_box(stream, camera_matrix, pose)
                self.draw_pose_axes(stream, camera_matrix, pose, tag.center)

            # Annotates the image
            if (annotate == True):
                self.annotate_detection(stream, tag)

            # Prints the Pose and calulated error
            if (verbose == 3):
                print(tag.tostring(collections.OrderedDict([("Pose", pose),
                                                            ("PoseError", err)]),
                                                            indent = 2))

            # Calculate Euler's Angles
            euler_angles = self.calculateEulerAngles(pose[:3, :3])

            # Adds results to the array
            result.extend([tag, pose, err])

            print("Tag", tag_num, "Rotation Matrix: \n", pose[:3, :3])
            print("Tag", tag_num, "Transformation Vectors: \n", pose[:3, 3:])
            print("Tag", tag_num, "3D Pose: \n", pose)
            print("Tag", tag_num, "Euler Angles: \n", euler_angles)

        return result, stream

    def atDetectTags(self, stream, camera_matrix, distortion_matrix, vizualization = 0, verbose = 0, annotate = False):
        """
        Detects AprilTags in a stream using apriltag.
        @param stream: A stream generated by reading a VideoCapture
        @param camera_matrix: The camera's calibration matrix
        @param distortion_matrix: The camera's distortion matrix
        @param vizualization [int]: 0 - Highlight, 1 - Highlight + Boxes, 2 - Highlight + Axes, 3 - Highlight + Boxes + Axes
        @param verbose [int]: 0 - Silent, 1 - Number of detections, 2 - Detection data, 3 - Detection and pose data
        @param annotate [bool]: Render annotated text on detection window
        @return detectionResult, image
        """
        # If the stream is not grayscale, convert to grayscale
        if (len(stream.shape) == 3):
            gray = cv.cvtColor(stream, cv.COLOR_BGR2GRAY)
        else:
            gray = stream
        
        # Detect the AprilTags in the image with the Official AprilTags library
        detections = self.atdetector.detect(gray)

        # If verbose enabled, prints number of tags detected
        num_detections = len(detections)
        if (verbose == 1) or (verbose == 2) or (verbose == 3):
            print("Detected {} tags\n".format(num_detections))

        # Creates the result array
        result = []

        # Access the 3D pose of all detected tag
        for i, tag in enumerate(detections):
            # Extract the corner points of the AprilTag
            tag_num       = tag["id"]
            corner_points = tag["lb-rb-rt-lt"]

            # Calculate the extrinsic parameters of the camera
            rotation_vector, translation_vector, __ = cv.aruco.estimatePoseSingleMarkers([corner_points], self.tag_size, camera_matrix, distortion_matrix)

            # Calculate the 3D pose of the AprilTag in the camera's coordinate system
            rotation_matrix, _ = cv.Rodrigues(rotation_vector)

            # Reshapes the array to the correct size
            tVecs = translation_vector[0].reshape(3, 1)

            # Creates a 3d pose array from the rotation matrix and translation vectors
            pose = np.concatenate([rotation_matrix, tVecs], axis = 1)

            # Prints debug info
            if (verbose == 2) or (verbose == 3):
                print( "Detection {} of {}:".format(i + 1, num_detections))
                print(tag.tostring(indent = 2))
                np.reshape(1, 3)

            # Draws varying levels of information onto the image
            if (vizualization == 1):
                self.draw_pose_box(stream, camera_matrix, pose)
            elif (vizualization == 2):
                self.draw_pose_axes(stream, camera_matrix, pose, tag["center"])
            elif (vizualization == 3):
                self.draw_pose_box(stream, camera_matrix, pose)
                self.draw_pose_axes(stream, camera_matrix, pose, tag["center"])

            # Annotates the image
            if (annotate == True):
                self.annotate_detection(stream, tag)

            # Prints the Pose and calulated error
            if (verbose == 3):
                print(tag.tostring(collections.OrderedDict([("Pose", pose)]),
                                                            indent = 2))

            # Calculate Euler's Angles
            euler_angles = self.calculateEulerAngles(pose[:3, :3])

            # Adds results to the array
            result.extend([tag, pose])

            print("Tag", tag_num, "Rotation Matrix: \n", pose[:3, :3])
            print("Tag", tag_num, "Transformation Vectors: \n", pose[:3, 3:])
            print("Tag", tag_num, "3D Pose: \n", pose)
            print("Tag", tag_num, "Euler Angles: \n", euler_angles)

        return result, stream

    def draw_pose_box(self, img, camera_matrix, pose, z_sign = 1):
        """
        Draws the 3d pose box around the AprilTag.
        @param img: The image to write on
        @param camera_matrix: The camera's calibration matrix
        @param pose: The 3d pose of the tag
        @param z_sign: The direction of the z-axis
        """
        # Creates object points
        opoints = np.array([
            -1, -1, 0,
            1, -1, 0,
            1,  1, 0,
            -1,  1, 0,
            -1, -1, -2 * z_sign,
            1, -1, -2 * z_sign,
            1,  1, -2 * z_sign,
            -1,  1, -2 * z_sign,
        ]).reshape(-1, 1, 3) * 0.5 * self.tag_size

        # Creates edges
        edges = np.array([
            0, 1,
            1, 2,
            2, 3,
            3, 0,
            0, 4,
            1, 5,
            2, 6,
            3, 7,
            4, 5,
            5, 6,
            6, 7,
            7, 4
        ]).reshape(-1, 2)

        # Calulcates rotation and translation vectors for each AprilTag
        rVecs, _ = cv.Rodrigues(pose[:3,:3])
        tVecs = pose[:3, 3:]

        # Derivative coefficients
        dcoeffs = np.zeros(5)

        # Calulate image points of each AprilTag
        ipoints, _ = cv.projectPoints(opoints, rVecs, tVecs, camera_matrix, dcoeffs)
        ipoints = np.round(ipoints).astype(int)
        ipoints = [tuple(pt) for pt in ipoints.reshape(-1, 2)]

        # Draws lines between all the edges
        for i, j in edges:
            cv.line(img, ipoints[i], ipoints[j], (0, 255, 0), 1, 16)

    def draw_pose_axes(self, img, camera_matrix, pose, center):
        """
        Draws the colored pose axes around the AprilTag.
        @param img: The image to write on
        @param camera_matrix: The camera's calibration matrix
        @param pose: The 3d pose of the tag
        @param center: The center of the AprilTag
        """
        # Calulcates rotation and translation vectors for each AprilTag
        rVecs, _ = cv.Rodrigues(pose[:3,:3])
        tVecs    = pose[:3, 3:]

        # Derivative coefficients
        dcoeffs = np.zeros(5)

        # Calculate object points of each AprilTag
        opoints = np.float32([[1, 0, 0],
                              [0, -1, 0],
                              [0, 0, -1]]).reshape(-1, 3) * self.tag_size

        # Calulate image points of each AprilTag
        ipoints, _ = cv.projectPoints(opoints, rVecs, tVecs, camera_matrix, dcoeffs)
        ipoints = np.round(ipoints).astype(int)

        # Calulates the center
        center = np.round(center).astype(int)
        center = tuple(center.ravel())

        # Draws the 3d pose lines
        cv.line(img, center, tuple(ipoints[0].ravel()), (0,0,255), 2)
        cv.line(img, center, tuple(ipoints[1].ravel()), (0,255,0), 2)
        cv.line(img, center, tuple(ipoints[2].ravel()), (255,0,0), 2)

    def annotate_detection(self, img, tag):
        """
        Annotates the image with coordinates.
        @param img: The image to write on
        @param detection: A detected AprilTag in the image
        """
        # Sets font
        font = cv.FONT_HERSHEY_SIMPLEX

        # Gets the tag properties
        text = str(tag.tag_id)
        tag_center = [tag.center[0], tag.center[1]]

        # Calulates the inner tag size
        tag_size_px = np.sqrt((tag.corners[1][0] - tag.corners[0][0]) ** 2 + (tag.corners[1][1] - tag.corners[0][1]) ** 2)

        # Gets font and text size
        font_size = tag_size_px / 22
        text_size = cv.getTextSize(text, font, font_size, 2)[0]

        # Gets the text position
        text_x = int(tag_center[0] - text_size[0] / 2)
        text_y = int(tag_center[1] + text_size[1] / 2)

        # Writes the text to the image
        cv.putText(img, text, (text_x, text_y), font, font_size, (0, 255, 255), 2)

    def calculateEulerAngles(self, rotationalMatrix):
        """
        Calculates Euler's Angles from a rotationMatrix
        @param rotationMatrix
        @return euler_angles_degrees
        """
        # Extract the tag data from the detection result
        if rotationalMatrix is not None:
            # Convert the rotation matrix to Euler angles using the sxyz convention
            euler_angles = transforms3d.euler.mat2euler(rotationalMatrix, "sxyz")

            # Convert the tuple of Euler angles to a NumPy array
            euler_angles = np.array(euler_angles)

            # Convert the Euler angles from radians to degrees
            euler_angles_degrees = euler_angles * 180/np.pi

            return euler_angles_degrees
        else:
            # Returns an array of zeros
            return np.zeros(3)